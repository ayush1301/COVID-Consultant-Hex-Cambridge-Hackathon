# -*- coding: utf-8 -*-
"""Face + mask detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Ktsrx164eQHfDmYLyMCoI-Kq0gC5Kg1
"""

!pip install -U retinaface_pytorch > /dev/null
!pip install facemask_detection  > /dev/null

!wget -O crowd.jpg https://habrastorage.org/webt/9e/pt/rs/9eptrsrhqoxcj1zbxzpadvn9gtu.jpeg > /dev/null

import cv2
import albumentations as A
import torch
import numpy as np

from tqdm import tqdm

from matplotlib import pyplot as plt
from retinaface.pre_trained_models import get_model as get_detector
from facemask_detection.pre_trained_models import get_model as get_classifier

plt.rcParams["figure.figsize"] = (15, 15)

image = cv2.imread("/content/output.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

plt.imshow(image)

face_detector = get_detector("resnet50_2020-07-20", max_size=800)

face_detector.eval()

with torch.no_grad():
  annotations = face_detector.predict_jsons(image)

len(annotations)

print(annotations)

mask_classifier = get_classifier("tf_efficientnet_b0_ns_2020-07-29")
mask_classifier.eval();

transform = A.Compose([A.SmallestMaxSize(max_size=256, p=1), 
                       A.CenterCrop(height=224, width=224, p=1),
                       A.Normalize(p=1)])

predictions = []

with torch.no_grad():
  for annotation in tqdm(annotations):
    x_min, y_min, x_max, y_max = annotation['bbox']

    x_min = np.clip(x_min, 0, x_max)
    y_min = np.clip(y_min, 0, y_max)
    
    crop = image[y_min:y_max, x_min:x_max]
    
    crop_transformed = transform(image=crop)['image']
    model_input = torch.from_numpy(np.transpose(crop_transformed, (2, 0, 1)))  

    predictions += [mask_classifier(model_input.unsqueeze(0))[0].item()]

vis_image = image.copy()
num_mask =0
num_no_mask=0

for prediction_id, annotation in enumerate(annotations):
    is_mask = predictions[prediction_id] > 0.5
    if is_mask:
      color = (0, 255, 0)    
      text = "mask"
      num_mask+=1
    else:
      color = (255, 0, 0)
      text = "no mask"
      num_no_mask+=1
    x_min, y_min, x_max, y_max = annotation["bbox"]

    x_min = np.clip(x_min, 0, x_max - 1)
    y_min = np.clip(y_min, 0, y_max - 1)

    vis_image = cv2.rectangle(vis_image, (x_min, y_min), (x_max, y_max), color=color, thickness=2)

    
    vis_image = cv2.putText(vis_image, text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX,  1, color, 2, cv2.LINE_AA) 

total_num= num_mask+num_no_mask

plt.imshow(vis_image)
print(f'Number with mask: {num_mask}')
print(num_no_mask)

